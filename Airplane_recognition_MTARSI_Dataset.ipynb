{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airplane_recognition_MTARSI_Dataset.ipynb",
      "provenance": [],
      "mount_file_id": "1D3PCmsdbhXUWzpB01_4ZOqM-BtoMOdWh",
      "authorship_tag": "ABX9TyNsi89XUUsP7kaONMgoTNBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gentleman101/Deep_Learning/blob/main/Airplane_recognition_MTARSI_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOV6Px_K_nx1"
      },
      "source": [
        "## Importing necessary packages\n",
        "\n",
        "Basic Idea will be to import a pre-trained model and then design a classifier on top of it. For our purpose I am taking inceptionV3 as our base model to identify object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaivJLI9jwR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N12Nz9geCf-r"
      },
      "source": [
        "## Importing Pre-Trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl__j3el_nT1"
      },
      "source": [
        "import keras\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Model,load_model\n",
        "# importing inception_v3 net from Keras with imagenet weights in conv_base\n",
        "conv_base =  InceptionV3(weights='imagenet',include_top=False,input_shape=(300, 300, 3))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqJ2c7l0C8g5"
      },
      "source": [
        "output = conv_base.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "model_tl = Model(conv_base.input, output)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOlVcIvDGAYh",
        "outputId": "eea9283b-dc4e-4c0b-f29d-75bd537d56db"
      },
      "source": [
        "# Setting all the base layers as untrainable\n",
        "model_tl.trainable = False\n",
        "for layer in model_tl.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# To read whether the layers are properly set or not\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in  model_tl.layers]\n",
        "model_layers=pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
        "print(model_layers) "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            Layer Type  ... Layer Trainable\n",
            "0    <keras.engine.input_layer.InputLayer object at...  ...           False\n",
            "1    <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
            "2    <keras.layers.normalization_v2.BatchNormalizat...  ...           False\n",
            "3    <keras.layers.core.Activation object at 0x7fa4...  ...           False\n",
            "4    <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
            "..                                                 ...  ...             ...\n",
            "307  <keras.layers.merge.Concatenate object at 0x7f...  ...           False\n",
            "308  <keras.layers.merge.Concatenate object at 0x7f...  ...           False\n",
            "309  <keras.layers.core.Activation object at 0x7fa4...  ...           False\n",
            "310  <keras.layers.merge.Concatenate object at 0x7f...  ...           False\n",
            "311  <keras.layers.core.Flatten object at 0x7fa4389...  ...           False\n",
            "\n",
            "[312 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6nC4MBjnOZF"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6AVnHvon1O1"
      },
      "source": [
        "#import splitfolders"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlMAyXrrn_RO"
      },
      "source": [
        "# Splitting the folder into 75% train and 25% test. I will form validation set using train data later\n",
        "#splitfolders.ratio('/content/drive/MyDrive/DATA/MTARSI/airplane-dataset-trans', output=\"'/content/drive/MyDrive/DATA/MTARSI/\", seed=1337, ratio=(.75, .25,), group_prefix=None) # default values"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6SWCELvHNSi"
      },
      "source": [
        "## Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNXomqaDG4Sm"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7mqNw38HisY"
      },
      "source": [
        "# Describing utility parameters\n",
        "batch_size=15\n",
        "epochs=30\n",
        "target_size=(300,300)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBXq9BTnr_IB"
      },
      "source": [
        "test_path='/content/drive/MyDrive/DATA/MTARSI/test_2'\n",
        "train_path='/content/drive/MyDrive/DATA/MTARSI/train_2'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTBviZOPsLVr"
      },
      "source": [
        "# Initiationg ImageDataGenerator on Keras to have a new augmented dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,  \n",
        "rotation_range=50,\n",
        "width_shift_range=0.2, \n",
        " height_shift_range=0.2, \n",
        "shear_range=0.2,\n",
        "horizontal_flip=True,\n",
        "brightness_range = [0.8, 1.2],\n",
        "fill_mode='nearest',        \n",
        " validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC8qrpqUvx6F",
        "outputId": "e5ecf3ac-8ca8-4236-a25a-d6cfe3ba4b82"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_path,\n",
        "target_size=target_size,#  \n",
        "batch_size=batch_size,\n",
        "class_mode='categorical',\n",
        "subset='training')\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "train_path,\n",
        "target_size=target_size,\n",
        "batch_size=batch_size,\n",
        "class_mode='categorical',\n",
        "subset='validation')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6979 images belonging to 23 classes.\n",
            "Found 1732 images belonging to 23 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf_-RUFoyUGk"
      },
      "source": [
        "## Building Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX-3sTRQyF2g"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras import optimizers"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "293QcqONybeZ",
        "outputId": "cd2b6729-0e0c-47de-97be-b8906c3e0995"
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model =Sequential()\n",
        "model.add(model_tl)\n",
        "# # hidden layer\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# # hidden layer\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# # hidden layer\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# # output layer\n",
        "model.add(Dense(23, activation='softmax'))\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_1 (Functional)         (None, 131072)            21802784  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 23)                3014679   \n",
            "=================================================================\n",
            "Total params: 24,817,463\n",
            "Trainable params: 3,014,679\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpgn9drcyLuO"
      },
      "source": [
        "## Creating Checkpoints for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii_bbjqYyCUY"
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath=\"/content/drive/My Drive/MyCNN/RR/epochs:{epoch:03d}-val_acc: {val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=False,save_freq='epoch',mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mdBETN6yZ7C"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGODnv8zyWxw",
        "outputId": "9e4d4e7f-3fa1-4e7b-b4d3-67b3879dc00b"
      },
      "source": [
        "history = model.fit(train_generator,steps_per_epoch=train_generator.samples//batch_size,validation_data=validation_generator,\n",
        "validation_steps=validation_generator.samples//batch_size,\n",
        "epochs=epochs,verbose=1,shuffle=True,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "465/465 [==============================] - 2599s 5s/step - loss: 4.2339 - acc: 0.2870 - val_loss: 4.1703 - val_acc: 0.3130\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/MyCNN/RR/epochs:001-val_acc: 0.313.hdf5\n",
            "Epoch 2/30\n",
            "465/465 [==============================] - 231s 497ms/step - loss: 2.2985 - acc: 0.5360 - val_loss: 3.8986 - val_acc: 0.4574\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/My Drive/MyCNN/RR/epochs:002-val_acc: 0.457.hdf5\n",
            "Epoch 3/30\n",
            "465/465 [==============================] - 232s 499ms/step - loss: 2.0068 - acc: 0.6094 - val_loss: 3.9944 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/My Drive/MyCNN/RR/epochs:003-val_acc: 0.477.hdf5\n",
            "Epoch 4/30\n",
            "465/465 [==============================] - 232s 499ms/step - loss: 1.8948 - acc: 0.6334 - val_loss: 3.9287 - val_acc: 0.4794\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/My Drive/MyCNN/RR/epochs:004-val_acc: 0.479.hdf5\n",
            "Epoch 5/30\n",
            "465/465 [==============================] - 235s 507ms/step - loss: 1.8562 - acc: 0.6501 - val_loss: 3.3933 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/MyCNN/RR/epochs:005-val_acc: 0.551.hdf5\n",
            "Epoch 6/30\n",
            "465/465 [==============================] - 233s 502ms/step - loss: 1.9061 - acc: 0.6554 - val_loss: 3.7987 - val_acc: 0.5229\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/My Drive/MyCNN/RR/epochs:006-val_acc: 0.523.hdf5\n",
            "Epoch 7/30\n",
            "465/465 [==============================] - 232s 499ms/step - loss: 1.8142 - acc: 0.6783 - val_loss: 3.1638 - val_acc: 0.5577\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/My Drive/MyCNN/RR/epochs:007-val_acc: 0.558.hdf5\n",
            "Epoch 8/30\n",
            "465/465 [==============================] - 233s 502ms/step - loss: 1.7818 - acc: 0.6871 - val_loss: 3.6371 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/My Drive/MyCNN/RR/epochs:008-val_acc: 0.537.hdf5\n",
            "Epoch 9/30\n",
            "465/465 [==============================] - 229s 493ms/step - loss: 1.8213 - acc: 0.6878 - val_loss: 3.0038 - val_acc: 0.5925\n",
            "\n",
            "Epoch 00009: saving model to /content/drive/My Drive/MyCNN/RR/epochs:009-val_acc: 0.592.hdf5\n",
            "Epoch 10/30\n",
            "465/465 [==============================] - 230s 496ms/step - loss: 1.7738 - acc: 0.7006 - val_loss: 3.0462 - val_acc: 0.5762\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/MyCNN/RR/epochs:010-val_acc: 0.576.hdf5\n",
            "Epoch 11/30\n",
            "465/465 [==============================] - 229s 492ms/step - loss: 1.6696 - acc: 0.7085 - val_loss: 3.3367 - val_acc: 0.5751\n",
            "\n",
            "Epoch 00011: saving model to /content/drive/My Drive/MyCNN/RR/epochs:011-val_acc: 0.575.hdf5\n",
            "Epoch 12/30\n",
            "465/465 [==============================] - 228s 492ms/step - loss: 1.7240 - acc: 0.7091 - val_loss: 3.2979 - val_acc: 0.5565\n",
            "\n",
            "Epoch 00012: saving model to /content/drive/My Drive/MyCNN/RR/epochs:012-val_acc: 0.557.hdf5\n",
            "Epoch 13/30\n",
            "192/465 [===========>..................] - ETA: 1:48 - loss: 1.8608 - acc: 0.7005"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cvkRX9Cgu6o"
      },
      "source": [
        "## Model Performance on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWZ0L2mV2GYD"
      },
      "source": [
        "model= load_model('/content/drive/My Drive/MyCNN/RR/epochs:012-val_acc: 0.557.hdf5')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xp257BSgtwR",
        "outputId": "c26e106a-53e6-434d-b90f-9bbf4e3e57fd"
      },
      "source": [
        "# Model evaluation\n",
        "scores_train = model.evaluate(train_generator,verbose=1)\n",
        "scores_validation = model.evaluate(validation_generator,verbose=1)\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores_train[1]*100))\n",
        "print(\"Validation Accuracy: %.2f%%\" % (scores_validation[1]*100))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "466/466 [==============================] - 1563s 3s/step - loss: 1.6912 - acc: 0.7114\n",
            "116/116 [==============================] - 386s 3s/step - loss: 3.3524 - acc: 0.5548\n",
            "Train Accuracy: 71.14%\n",
            "Validation Accuracy: 55.48%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ubTbPQyeaq"
      },
      "source": [
        "#For plotting Accuracy and Loss\n",
        "def LearningCurve(history):\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m9_vqrcMV8d"
      },
      "source": [
        "LearningCurve(history)  # Couldn't put this as session timedout after 13th epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYYSJQZBa4gh"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPbDXnKlp6fw"
      },
      "source": [
        "import math\n",
        "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))\n",
        "test_steps = compute_steps_per_epoch(100)\n",
        "test_generator = test_datagen.flow_from_directory(test_path,target_size=target_size, batch_size=batch_size,class_mode=None,shuffle=False)\n",
        "test_generator.reset()\n",
        "#Calling the saved model for making predictions\n",
        "tl_img_aug_cnn = load_model('/content/drive/My Drive/MyCNN/RR/epochs:025-val_acc: 0.592.hdf5')\n",
        "pred=tl_img_aug_cnn.predict(test_generator,verbose=1,steps=test_steps)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = (test_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames, \"Predictions\":predictions})\n",
        "#create a function for visualizing model performance\n",
        "import seaborn as sns\n",
        "def PerformanceReports(conf_matrix,class_report,labels):\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(conf_matrix, annot=True,ax=ax)\n",
        "    #labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(labels)\n",
        "    ax.yaxis.set_ticklabels(labels)\n",
        "    plt.show()\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(pd.DataFrame(class_report).iloc[:-1, :].T,  annot=True,ax=ax)\n",
        "    ax.set_title('Classification Report')\n",
        "    plt.show()\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "labels=['A','A-10','A-26','B-1','B-2','B-29','B-52','Background','Boeing','C-5','C-17','C-21','C-130','C-135','E-3','F','F-16','F-22','KC-10','P-63','T-6','t-43','U-2']\n",
        "test_labels = [fn.split('/')[0] for fn in filenames]\n",
        "cm=confusion_matrix(test_labels,predictions)\n",
        "print(cm)\n",
        "cr=classification_report(test_labels, predictions)\n",
        "class_report=classification_report(test_labels, predictions,target_names=labels,output_dict=True)\n",
        "print(cr)\n",
        "PerformanceReports(cm,class_report,labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}