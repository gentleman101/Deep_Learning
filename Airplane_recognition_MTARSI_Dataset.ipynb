{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airplane_recognition_MTARSI_Dataset.ipynb",
      "provenance": [],
      "mount_file_id": "1D3PCmsdbhXUWzpB01_4ZOqM-BtoMOdWh",
      "authorship_tag": "ABX9TyM+8rdqx9WKTF2u0qbshaCp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gentleman101/Deep_Learning/blob/main/Airplane_recognition_MTARSI_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOV6Px_K_nx1"
      },
      "source": [
        "## Importing necessary packages\n",
        "\n",
        "Basic Idea will be to import a pre-trained model and then design a classifier on top of it. For our purpose I am taking inceptionV3 as our base model to identify object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaivJLI9jwR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N12Nz9geCf-r"
      },
      "source": [
        "## Importing Pre-Trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl__j3el_nT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902af2e0-3d5b-4257-88c3-71759abfcc6b"
      },
      "source": [
        "import keras\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Model,load_model\n",
        "# importing inception_v3 net from Keras with imagenet weights in conv_base\n",
        "conv_base =  InceptionV3(weights='imagenet',include_top=False,input_shape=(300, 300, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqJ2c7l0C8g5"
      },
      "source": [
        "output = conv_base.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "model_tl = Model(conv_base.input, output)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOlVcIvDGAYh",
        "outputId": "1446f1d0-3dc9-470d-a888-6db60f07e24b"
      },
      "source": [
        "# Setting all the base layers as untrainable\n",
        "model_tl.trainable = False\n",
        "for layer in model_tl.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# To read whether the layers are properly set or not\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in  model_tl.layers]\n",
        "model_layers=pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
        "print(model_layers) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            Layer Type  ... Layer Trainable\n",
            "0    <keras.engine.input_layer.InputLayer object at...  ...           False\n",
            "1    <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
            "2    <keras.layers.normalization_v2.BatchNormalizat...  ...           False\n",
            "3    <keras.layers.core.Activation object at 0x7fcc...  ...           False\n",
            "4    <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
            "..                                                 ...  ...             ...\n",
            "307  <keras.layers.merge.Concatenate object at 0x7f...  ...           False\n",
            "308  <keras.layers.merge.Concatenate object at 0x7f...  ...           False\n",
            "309  <keras.layers.core.Activation object at 0x7fcb...  ...           False\n",
            "310  <keras.layers.merge.Concatenate object at 0x7f...  ...           False\n",
            "311  <keras.layers.core.Flatten object at 0x7fcbfa6...  ...           False\n",
            "\n",
            "[312 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6nC4MBjnOZF"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6AVnHvon1O1"
      },
      "source": [
        "#import splitfolders"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlMAyXrrn_RO"
      },
      "source": [
        "# Splitting the folder into 75% train and 25% test. I will form validation set using train data later\n",
        "#splitfolders.ratio('/content/drive/MyDrive/DATA/MTARSI/airplane-dataset-trans', output=\"'/content/drive/MyDrive/DATA/MTARSI/\", seed=1337, ratio=(.75, .25,), group_prefix=None) # default values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6SWCELvHNSi"
      },
      "source": [
        "## Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNXomqaDG4Sm"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7mqNw38HisY"
      },
      "source": [
        "# Describing utility parameters\n",
        "batch_size=15\n",
        "epochs=30\n",
        "target_size=(300,300)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBXq9BTnr_IB"
      },
      "source": [
        "test_path='/content/drive/MyDrive/DATA/MTARSI/test_2'\n",
        "train_path='/content/drive/MyDrive/DATA/MTARSI/train_2'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTBviZOPsLVr"
      },
      "source": [
        "# Initiationg ImageDataGenerator on Keras to have a new augmented dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,  \n",
        "rotation_range=50,\n",
        "width_shift_range=0.2, \n",
        " height_shift_range=0.2, \n",
        "shear_range=0.2,\n",
        "horizontal_flip=True,\n",
        "brightness_range = [0.8, 1.2],\n",
        "fill_mode='nearest',        \n",
        " validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC8qrpqUvx6F",
        "outputId": "f7cee789-e588-4e28-ee88-f7916743f7be"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_path,\n",
        "target_size=target_size,#  \n",
        "batch_size=batch_size,\n",
        "class_mode='categorical',\n",
        "subset='training')\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "train_path,\n",
        "target_size=target_size,\n",
        "batch_size=batch_size,\n",
        "class_mode='categorical',\n",
        "subset='validation')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6979 images belonging to 23 classes.\n",
            "Found 1732 images belonging to 23 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf_-RUFoyUGk"
      },
      "source": [
        "## Building Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX-3sTRQyF2g"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras import optimizers"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "293QcqONybeZ",
        "outputId": "1ea9c661-7bf0-4eac-f176-1fa367a920c5"
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model =Sequential()\n",
        "model.add(model_tl)\n",
        "# # hidden layer\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# # hidden layer\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# # hidden layer\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# # output layer\n",
        "model.add(Dense(23, activation='softmax'))\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model (Functional)           (None, 131072)            21802784  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 23)                3014679   \n",
            "=================================================================\n",
            "Total params: 24,817,463\n",
            "Trainable params: 3,014,679\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpgn9drcyLuO"
      },
      "source": [
        "## Creating Checkpoints for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii_bbjqYyCUY"
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath=\"/content/drive/My Drive/MyCNN/RR/epochs:{epoch:03d}-val_acc: {val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=False,save_freq='epoch',mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mdBETN6yZ7C"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGODnv8zyWxw",
        "outputId": "9e4d4e7f-3fa1-4e7b-b4d3-67b3879dc00b"
      },
      "source": [
        "history = model.fit(train_generator,steps_per_epoch=train_generator.samples//batch_size,validation_data=validation_generator,\n",
        "validation_steps=validation_generator.samples//batch_size,\n",
        "epochs=epochs,verbose=1,shuffle=True,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "465/465 [==============================] - 2599s 5s/step - loss: 4.2339 - acc: 0.2870 - val_loss: 4.1703 - val_acc: 0.3130\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/MyCNN/RR/epochs:001-val_acc: 0.313.hdf5\n",
            "Epoch 2/30\n",
            "465/465 [==============================] - 231s 497ms/step - loss: 2.2985 - acc: 0.5360 - val_loss: 3.8986 - val_acc: 0.4574\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/My Drive/MyCNN/RR/epochs:002-val_acc: 0.457.hdf5\n",
            "Epoch 3/30\n",
            "465/465 [==============================] - 232s 499ms/step - loss: 2.0068 - acc: 0.6094 - val_loss: 3.9944 - val_acc: 0.4771\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/My Drive/MyCNN/RR/epochs:003-val_acc: 0.477.hdf5\n",
            "Epoch 4/30\n",
            "465/465 [==============================] - 232s 499ms/step - loss: 1.8948 - acc: 0.6334 - val_loss: 3.9287 - val_acc: 0.4794\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/My Drive/MyCNN/RR/epochs:004-val_acc: 0.479.hdf5\n",
            "Epoch 5/30\n",
            "465/465 [==============================] - 235s 507ms/step - loss: 1.8562 - acc: 0.6501 - val_loss: 3.3933 - val_acc: 0.5513\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/MyCNN/RR/epochs:005-val_acc: 0.551.hdf5\n",
            "Epoch 6/30\n",
            "465/465 [==============================] - 233s 502ms/step - loss: 1.9061 - acc: 0.6554 - val_loss: 3.7987 - val_acc: 0.5229\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/My Drive/MyCNN/RR/epochs:006-val_acc: 0.523.hdf5\n",
            "Epoch 7/30\n",
            "465/465 [==============================] - 232s 499ms/step - loss: 1.8142 - acc: 0.6783 - val_loss: 3.1638 - val_acc: 0.5577\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/My Drive/MyCNN/RR/epochs:007-val_acc: 0.558.hdf5\n",
            "Epoch 8/30\n",
            "465/465 [==============================] - 233s 502ms/step - loss: 1.7818 - acc: 0.6871 - val_loss: 3.6371 - val_acc: 0.5374\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/My Drive/MyCNN/RR/epochs:008-val_acc: 0.537.hdf5\n",
            "Epoch 9/30\n",
            "465/465 [==============================] - 229s 493ms/step - loss: 1.8213 - acc: 0.6878 - val_loss: 3.0038 - val_acc: 0.5925\n",
            "\n",
            "Epoch 00009: saving model to /content/drive/My Drive/MyCNN/RR/epochs:009-val_acc: 0.592.hdf5\n",
            "Epoch 10/30\n",
            "465/465 [==============================] - 230s 496ms/step - loss: 1.7738 - acc: 0.7006 - val_loss: 3.0462 - val_acc: 0.5762\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/My Drive/MyCNN/RR/epochs:010-val_acc: 0.576.hdf5\n",
            "Epoch 11/30\n",
            "465/465 [==============================] - 229s 492ms/step - loss: 1.6696 - acc: 0.7085 - val_loss: 3.3367 - val_acc: 0.5751\n",
            "\n",
            "Epoch 00011: saving model to /content/drive/My Drive/MyCNN/RR/epochs:011-val_acc: 0.575.hdf5\n",
            "Epoch 12/30\n",
            "465/465 [==============================] - 228s 492ms/step - loss: 1.7240 - acc: 0.7091 - val_loss: 3.2979 - val_acc: 0.5565\n",
            "\n",
            "Epoch 00012: saving model to /content/drive/My Drive/MyCNN/RR/epochs:012-val_acc: 0.557.hdf5\n",
            "Epoch 13/30\n",
            "192/465 [===========>..................] - ETA: 1:48 - loss: 1.8608 - acc: 0.7005"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cvkRX9Cgu6o"
      },
      "source": [
        "## Model Performance on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWZ0L2mV2GYD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xp257BSgtwR"
      },
      "source": [
        "# Model evaluation\n",
        "scores_train = model.evaluate(train_generator,verbose=1)\n",
        "scores_validation = model.evaluate(validation_generator,verbose=1)\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores_train[1]*100))\n",
        "print(\"Validation Accuracy: %.2f%%\" % (scores_validation[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ubTbPQyeaq"
      },
      "source": [
        "#For plotting Accuracy and Loss\n",
        "def LearningCurve(history):\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXBHR34MhJwD"
      },
      "source": [
        "LearningCurve(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYYSJQZBa4gh"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H80J7RKghNOV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "e7691ab8-32c9-43f2-9d9e-0e13770d827e"
      },
      "source": [
        "import math\n",
        "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))\n",
        "test_steps = compute_steps_per_epoch(100)\n",
        "test_generator = test_datagen.flow_from_directory(test_path,target_size=target_size, batch_size=batch_size,class_mode=None,shuffle=False)\n",
        "test_generator.reset()\n",
        "#Calling the saved model for making predictions\n",
        "tl_img_aug_cnn = load_model('/content/drive/My Drive/MyCNN/RR/epochs:025-val_acc: 0.592.hdf5')\n",
        "pred=tl_img_aug_cnn.predict(test_generator,verbose=1,steps=test_steps)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = (test_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames, \"Predictions\":predictions})\n",
        "#create a function for visualizing model performance\n",
        "import seaborn as sns\n",
        "def PerformanceReports(conf_matrix,class_report,labels):\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(conf_matrix, annot=True,ax=ax)\n",
        "    #labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(labels)\n",
        "    ax.yaxis.set_ticklabels(labels)\n",
        "    plt.show()\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(pd.DataFrame(class_report).iloc[:-1, :].T,  annot=True,ax=ax)\n",
        "    ax.set_title('Classification Report')\n",
        "    plt.show()\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "labels=['A','A-10','A-26','B-1','B-2','B-29','B-52','Background','Boeing','C-5','C-17','C-21','C-130','C-135','E-3','F','F-16','F-22','KC-10','P-63','T-6','t-43','U-2']\n",
        "test_labels = [fn.split('/')[0] for fn in filenames]\n",
        "cm=confusion_matrix(test_labels,predictions)\n",
        "print(cm)\n",
        "cr=classification_report(test_labels, predictions)\n",
        "class_report=classification_report(test_labels, predictions,target_names=labels,output_dict=True)\n",
        "print(cr)\n",
        "PerformanceReports(cm,class_report,labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2978 images belonging to 23 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-274f02af997c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Calling the saved model for making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtl_img_aug_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/MyCNN/RR/epochs:025-val_acc: 0.592.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtl_img_aug_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpredicted_class_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    955\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 957\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 1280000 values, but the requested shape requires a multiple of 131072\n\t [[node sequential_1/model/flatten/Reshape (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core.py:672) ]] [Op:__inference_predict_function_65960]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/model/flatten/Reshape:\n sequential_1/model/mixed10/concat (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:3063)\t\n sequential_1/model/flatten/Const (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core.py:667)\n\nFunction call stack:\npredict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPbDXnKlp6fw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}